version: 0.2

env:
  variables:
    GLUE_JOB_NAME: "json_to_parquet"
    RESET_BOOKMARK: "false"
    DOCS_BUCKET: "starbust-dbt-docs"
  secrets-manager:
    TRINO_URL: "prod/dbt/starburst:TRINO_URL"
    DBT_TRINO_USER: "prod/dbt/starburst:DBT_TRINO_USER"
    DBT_TRINO_PASSWORD: "prod/dbt/starburst:DBT_TRINO_PASSWORD"
    DBT_SCHEMA: "prod/dbt/starburst:DBT_SCHEMA"

phases:
  install:
    runtime-versions:
      python: 3.11
    commands:
      - echo "Checking python version..."
      - python --version
      - pip install --upgrade pip
      - pip install "urllib3<2.0"
      - pip install "protobuf>=4.21.1,<5.0.0"
      - pip install dbt-core==1.7.4 dbt-trino==1.7.1

  build:
    commands:
      - echo "Verifying installations..."
      - dbt --version
      - echo "dbt build process starting..."
      - cd cust_tran
      
      # ----------------------------------------------------------------
      # STEP 1: TRIGGER AWS GLUE JOB (BLOCKING)
      # ----------------------------------------------------------------
      - echo "Triggering Glue Job $GLUE_JOB_NAME with Bookmark Reset $RESET_BOOKMARK"
      

      - |
        JOB_ARGS="{\"--reset_bookmark\": \"${RESET_BOOKMARK}\"}"
        
        JOB_RUN_ID=$(aws glue start-job-run \
          --job-name "$GLUE_JOB_NAME" \
          --arguments "$JOB_ARGS" \
          --query 'JobRunId' \
          --output text)
      
      - echo "Glue Job started. Run ID $JOB_RUN_ID. Waiting for completion..."
      
      # Poll the status
      - |
        while :; do
          STATUS=$(aws glue get-job-run --job-name "$GLUE_JOB_NAME" --run-id "$JOB_RUN_ID" --query 'JobRun.JobRunState' --output text)
          echo "Current Glue Job Status: $STATUS"
          if [ "$STATUS" == "SUCCEEDED" ]; then
            echo "Glue Job finished successfully! Proceeding to dbt..."
            break
          elif [ "$STATUS" == "FAILED" ] || [ "$STATUS" == "STOPPED" ] || [ "$STATUS" == "TIMEOUT" ]; then
            echo "Error: Glue Job failed. Stopping build."
            exit 1
          fi
          sleep 15
        done

      # ----------------------------------------------------------------
      # STEP 2: DBT TRANSFORMATION
      # ----------------------------------------------------------------
      - export RUN_DATE=$(date -d "$(date +%Y-%m-01) -1 month" +%Y-%m-%d)
      - echo "------------------------------------------------"
      - echo "Processing Data For Business Date $RUN_DATE"
      - echo "------------------------------------------------"
      - dbt clean 
      - dbt deps
      - dbt run-operation force_create_external_tables
      - "dbt run --select models/core --vars '{\"initial_load\": true}'"
      - "dbt run --select models/gold --vars \"{\\\"business_date\\\": \\\"$RUN_DATE\\\"}\""
      - dbt run --select models/consumption_views

      # ----------------------------------------------------------------
      # STEP 3: GENERATE & HOST DOCS
      # ----------------------------------------------------------------
      - echo "Generating dbt documentation for $RUN_DATE..."
      
      # Generate the static HTML/JSON files
      - "dbt docs generate --vars \"{\\\"business_date\\\": \\\"$RUN_DATE\\\"}\""
      
      - echo "Uploading docs to S3 Website..."
      # Sync the 'target' folder to your S3 bucket
      # We exclude the compiled SQL files to save space, keeping only the web assets
      - "aws s3 sync target/ s3://$DOCS_BUCKET/ --delete --exclude 'compiled/*' --exclude 'run/*' --exclude 'example/*'"
      
      - 'echo "Docs deployed! Access them at: http://$DOCS_BUCKET.s3-website.us-east-2.amazonaws.com"'
